{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f9c39e",
   "metadata": {},
   "source": [
    "# Kunskapskontroll 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db5c1e-04b4-4663-bd52-99c7cfbf3871",
   "metadata": {},
   "source": [
    "### Fyll i uppgifterna nedan (obligatoriskt för att bli godkänd) innan du lämnar in på Omniway: \n",
    "Namn: \n",
    "\n",
    "Datum då du presenterade ditt arbete på lektionen: 2024-02-21\n",
    "\n",
    "Presenterade du inte det på lektionen, skriv vem du har diskuterat igenom koden med: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9240d4-6646-48ae-8837-45a0f0b34827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34dbb2c8-9ee6-4d36-837c-adac438d7e83",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1456e",
   "metadata": {},
   "source": [
    "As a data analyst there is plenty of opportunity to improve processes or suggest improved ways of doing things. When doing so it is often very smart and efficient (time is a scarce resource) to create a POC (Proof of Concept) which basically is a small demo checking wether it is worthwile going further with something. It is also something concrete which facilitates discussions, do not underestimate the power of that. \n",
    "\n",
    "In this example, you are working in a company that sells houses and they have a \"manual\" process of setting prices by humans. You as a Data Scientist can make this process better by using Machine Learning. Your task is to create a POC that you will present to your team colleagues and use as a source of discussion of wether or not you should continue with more detailed modelling. \n",
    "\n",
    "Two quotes to facilitate your reflection on the value of creating a PoC: \n",
    "\n",
    "\"*Premature optimization is the root of all evil*\". \n",
    "\n",
    "\"*Fail fast*\".\n",
    "\n",
    "\n",
    "**More specifially, do the following:**\n",
    "1. A short EDA (Exploratory Data Analysis) of the housing data set.\n",
    "2. Drop the column \"ocean_proximity\", then you only have numeric columns which will simplify your analysis. Remember, this is a POC!\n",
    "3. Split your data into train and test set.\n",
    "4. You have missing values in your data. Handle this with [ SimpleImputer(strategy=\"median\") ], check the fantastic Scikit-learn documentation for details.\n",
    "5. Create one \"Linear Regression\" model and one \"Lasso\" model. For the Lasso model, use GridSearchCV to optimize $\\alpha$ values, choose yourself which $\\alpha$ values to evaluate.\n",
    "Use RMSE as a metric to decide which model to choose. \n",
    "\n",
    "7. Evaluate your chosen model on the test set using the root mean squared error (RMSE) as the metric. Conclusions? \n",
    "\n",
    "8. Do a short presentation (~ 2-5 min) on your POC that you present to your colleagues (no need to prepare anything particular, just talk from the code). Think of:\n",
    "- What do you want to highlight/present?\n",
    "- What is your conclusion?\n",
    "- What could be the next step? Is the POC convincing enough or is it not worthwile continuing? Do we need to dig deeper into this before taking some decisions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96931ff",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4fcb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147ea5de",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Below, set your own path where you have stored the data file. \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m housing \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousing.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing.csv'"
     ]
    }
   ],
   "source": [
    "# Below, set your own path where you have stored the data file. \n",
    "housing = pd.read_csv(r'housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22dbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41340b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing.drop('ocean_proximity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5c05f-7b43-4319-bbd6-0e8fe93cd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc651a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.drop('median_house_value', axis=1)\n",
    "y = housing['median_house_value'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3ce1f-de01-4ac9-a79d-e3eabcaf29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43daf6d-44eb-48ae-b38c-e8f4f6f330c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b334b039-6ceb-457a-9819-bc86bf6d1fc8",
   "metadata": {},
   "source": [
    "Kalle kommer till vår mäklarfirma. \n",
    "Han säger att områdets median inkomst är 8000, det finns 900 rum ,....\n",
    "--> Vi predikterar ett rimligt pris för huset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def60d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee19169",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d969e-e231-44be-84ab-341b37c19ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train.copy()\n",
    "df['target'] = y_train\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221ea71-5faa-4664-a0c3-2d63ff7b3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca06972d",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be80771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "steps = [\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit pipeline and transform training data\n",
    "X_train_prepared = pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa732d75",
   "metadata": {},
   "source": [
    "## Validating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and cross validate linear regression model\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg_scores = cross_val_score(linreg, X_train_prepared, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "linreg_rmses = np.sqrt(-linreg_scores)\n",
    "print(f'Average Linear Regression RMSE: {np.mean(linreg_rmses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5313d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Lasso model, find best alpha value using GridSearch\n",
    "\n",
    "lasso = Lasso()\n",
    "params = {\n",
    "    'alpha': [1, 10, 41, 50]\n",
    "}\n",
    "lasso_reg = GridSearchCV(lasso, params, cv=5)\n",
    "lasso_reg.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(lasso_reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate Lasso model\n",
    "\n",
    "lasso_reg_scores = cross_val_score(lasso_reg, X_train_prepared, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "lasso_reg_rmses = np.sqrt(-lasso_reg_scores)\n",
    "print(f'Average Lasso RMSE: {np.mean(lasso_reg_rmses)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503648fd",
   "metadata": {},
   "source": [
    "### Findings\n",
    "The Lasso model performs ever so slightly better than the Linear regression model with a difference of $13.14$.\n",
    "\n",
    "The Lasso model will be used to predict against the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0075384",
   "metadata": {},
   "source": [
    "## Final testing of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119939db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "\n",
    "X_test_prepared = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f66ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using Lasso model\n",
    "\n",
    "lasso_pred = lasso_reg.predict(X_test_prepared)\n",
    "lasso_RMSE = mean_squared_error(y_test, lasso_pred, squared=False)\n",
    "\n",
    "print(lasso_RMSE)\n",
    "print(lasso_RMSE/y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000e06d-f02e-422c-9ed8-af0af499a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269466b",
   "metadata": {},
   "source": [
    "### Quick conclusion\n",
    "The lasso model performs ever so slightly better than the linear regression model.\n",
    "\n",
    "However, the RMSE of the model is a bit over $70000, which is about 35% of the mean house value. Further steps to fine tune the model could be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linreg.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2285b1",
   "metadata": {},
   "source": [
    "###### ---- End ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446fb70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
